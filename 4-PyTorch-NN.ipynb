{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                  transform = transforms.Compose([\n",
    "                      transforms.ToTensor()\n",
    "                  ]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                  transform = transforms.Compose([\n",
    "                      transforms.ToTensor()\n",
    "                  ]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn provides an OO interface (initialsing) while F is functional (parameters)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# python: Net inherits methods from nn.Module, calling super will call the nn.Module (parent) init function.\n",
    "\n",
    "class Net(nn.Module):\n",
    "    '''\n",
    "    __init__: \n",
    "        - fc1 is fully connected first layer\n",
    "            - the first layer fc1 is input, it outputs to fc2 so we pass the same size from the output of fc1 to the input of fc2\n",
    "            - the output layer fc4 has a size of 10 to represent each of our ten digits\n",
    "        - nn.Linear(input, output), \n",
    "            - input (size of each input sample) are our images, each image is 28 by 28 pixels so a flattend image is 28*28=784\n",
    "            - output (size of each output sample) will have 3 layers of 64 neurons for our hidden layers\n",
    "\n",
    "    forward: \n",
    "        - Feed Forward Network, as simple as it gets, one layers output is passed to the next layers output\n",
    "        - Most people use the same optimizer function like relu, things change with regards to output, for us the output is multi class and log softmax \n",
    "          works to give a probability distribution. Note that the size of the output is the number if outputs, one for each of our ten digits.\n",
    "        - F.relu() is being run over an entire layers output, relu (rectifide linear) is the activation function or optimizer, it is a sigmoid\n",
    "          for firing or not firing of 'neurons'\n",
    "        - F.log_softmax() takes the output and dimension to output a probability distribution, recall that the goal with output \n",
    "          is to see which neurons fired, so whichever one is closer to 1 then that is the 'most fired' neuron. Because we are dealing with \n",
    "          multiple classes we want a probability distribution on the output.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)   # input to hidden\n",
    "        self.fc2 = nn.Linear(64, 64)      # hidden\n",
    "        self.fc3 = nn.Linear(64, 64)      # hidden\n",
    "        self.fc4 = nn.Linear(64, 10)      # hidden to output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))   # x is the output ( nn.Linear(64, x) ), pass result of fc1 to relu\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)           # for the output we want to output a probability distribution\n",
    "\n",
    "        # probability distribution log_softmax, dimension is 1 as we assume a flat multi dim array tensor for final x (output)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        \n",
    "net = Net()   \n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1, 28*28)    # -1 tells the reshape/view to expect data at any size Tensor(multi dimen array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3946, -2.4483, -2.1444, -2.4615, -2.2429, -2.1308, -2.1603, -2.2806,\n",
       "         -2.4420, -2.4023]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output # these are the outputs !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.1308, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.max() # max value will be at index, the index is the predicted value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "Up to this point, we've gotton the data (builtin dataset), we've built the neural network and passed some data through the neural network and we get a response.\n",
    "\n",
    "But now we want to pass through labeled data and train the model to be able to recognize hand written digits from data its never seen before.\n",
    "In order to acheive this, we'll need to learn about loss and the optimizer.\n",
    "\n",
    "Loss is simply how wrong the model is, the goal with loss is to have it decrease over time.\n",
    "The optimizers job is to go and adjust the weights that it can, based on the loss (gradients) to lower the loss. Learning rate is the step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  # net.parameters() is everything that is adjustable within the model\n",
    "\n",
    "EPOCHS = 3  # a full pass through of all the data is called an epoch \n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is a batch of featuresets and labels (targets)\n",
    "        # featuresets are the images (X[i]), labels are the class names (y[i]) like a 1,2,3,4,5...\n",
    "        X, y = data\n",
    "        # everytime before you pass data through the NN start with a zero gradient\n",
    "        # zero gradients can help with lowering batch size if hardware resources are limited, the way it does this is that as each wave of data that flows through \n",
    "        # the NN the data are added together to calculate weights for each of the features, interupting the flow with a wave of zeros will 'reset' or 'seperate'\n",
    "        # a data into an artificial batch, more batches are better as it gives the optimizer a way to compare outputs of hidden layers and adjust for loss.\n",
    "        # the gradients contain the loss, the optimizer uses the gradients to optimize the weights.\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()    # back propigate loss over model parameters\n",
    "        optimizer.step()   # will adjust the weights for us\n",
    "    print(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.979\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "\n",
    "# when validating data we don't want gradients to be calculated, this is out of sample data\n",
    "# so we use torch with no gradient (no_grad), we just want to know how good the NN is at this point\n",
    "with torch.no_grad():  \n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        for idx, i in enumerate(output):      # i is an output Tensor\n",
    "            if(torch.argmax(i) == y[idx]):    # if the max value in i is the same at the index of y, then because the digits correspond to their index, correct+=1\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print('Accuracy: ', round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[8].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2, grad_fn=<NotImplemented>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[8].view(-1, 28*28))[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
